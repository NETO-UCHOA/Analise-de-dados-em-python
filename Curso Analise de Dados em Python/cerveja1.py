#!/usr/bin/env python
# coding: utf-8

# In[38]:


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
import statsmodels.stats.api as sms

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

from statsmodels.graphics.tsaplots import plot_acf
from statsmodels.graphics.gofplots import qqplot
from statsmodels.compat import lzip


# Todo processo come√ßa com uma an√°lise dos dados, o conhecimento da base a ser analisada √© de fundamental import√¢ncia, assim como qual √© o objetivo (previs√£o) que queremos chegar.
# 
# Os dados (amostra) foram coletados em S√£o Paulo ‚Äî Brasil, em uma √°rea universit√°ria, onde acontecem algumas festas com turmas de alunos de 18 a 28 anos (m√©dia). O conjunto de dados utilizado para esta atividade possui 7 vari√°veis, sendo uma vari√°vel dependente, com per√≠odo de um ano.
# 
# Nossa vari√°vel dependente(objetivo) √© o consumo de cerveja em litros.

# In[2]:


df = pd.read_csv("D:\\lixo\\Consumo_cerveja.csv")


# In[3]:


display(df)
# o comando display(df) pode ser reproduzido tamb√©m com 
#df.head()
#df.tail()
#df.shape


# In[4]:


df.info()
# o comando df,info() pode ser reproduzido tamb√©m com
#df.isna().sum()
#df.dtypes


# In[5]:


df.describe()


# Uma informa√ß√£o muito inportante para a an√°lise √© saber como as vari√°veis est√£o correlacionadas entre si, em especial como a vari√°vel dependente se correlaciona com cada uma das vari√°veis independentes

# In[6]:


df.corr(numeric_only=True)


# Como se espera a quantidade de dias que n√£o s√£o sinal de semana √© maior que a quantidade de dias que s√£o final de semana

# In[7]:


plt.figure(figsize=(15,7))
sns.countplot(x='Final de Semana', data=df)
plt.xlabel('Final de Semana')
plt.ylabel('');


# In[8]:


df[['Temperatura Media (C)', 
         'Temperatura Minima (C)',
         'Temperatura Maxima (C)']].plot(figsize=(15,7));
plt.title('S√©ries de temperaturas m√°ximas, M√©dias e M√≠nimas', size=15);


# In[9]:


df['Precipitacao (mm)'].plot(figsize=(15,7))
plt.title('Precipita√ß√£o em mm',size=15);


# In[10]:


df['Consumo de cerveja (litros)'].plot(figsize=(15,7), color='black');
plt.title('Consumo de cerveja',size=15);


# In[11]:


plt.figure(figsize=(15,7))
sns.heatmap(df.corr(numeric_only=True), annot = True, cmap= "RdYlGn");
plt.title('Correla√ß√£o de Pearson',size=15);


# In[12]:


plt.figure(figsize=(15,7))
plt.title('Correla√ß√£o de Spearman',size=15)
sns.heatmap(df.corr('spearman',numeric_only=True), annot = True, cmap= "Miscellaneous");


# In[13]:


df[['Temperatura Media (C)', 'Temperatura Minima (C)',
       'Temperatura Maxima (C)', 'Precipitacao (mm)',
       'Consumo de cerveja (litros)']].plot.box(figsize=(15,7));


# In[14]:


df[['Temperatura Media (C)', 'Temperatura Minima (C)',
       'Temperatura Maxima (C)', 'Precipitacao (mm)',
       'Consumo de cerveja (litros)']].hist(figsize=(15,7), bins=50);


# In[15]:


fig,ax = plt.subplots(2,2, figsize=(15,7))
sns.scatterplot(x='Consumo de cerveja (litros)',y='Temperatura Media (C)',data = df,ax=ax[0][0]);
sns.scatterplot(x='Consumo de cerveja (litros)',y='Temperatura Minima (C)',data = df,ax=ax[0][1]);
sns.scatterplot(x='Consumo de cerveja (litros)',y='Temperatura Maxima (C)',data = df,ax=ax[1][0]);
sns.scatterplot(x='Consumo de cerveja (litros)',y='Precipitacao (mm)',data = df,ax=ax[1][1]);


# ### Regress√£o linear m√∫ltipla em Python
# Existem tr√™s formas de estimar o modelo de regress√£o m√∫ltipla em Python:
# 
# Biblioteca Scikit Learn : que √© mais voltada para resolu√ß√£o de problemas de machine learning e por esse motivo √© limitada, principalmente para gerar modelos inferenciais;
# 
# Biblioteca Pingouin : √© mais sofisticada que a Scikit Learn gerando mais estat√≠sticas e resultados do modelo;
# 
# Biblioteca Statsmodels : mais completa para gerar o modelo, permitindo a realiza√ß√£o de testes para an√°lise e diagn√≥stico.
# 
# Para fins de demonstra√ß√£o ser√° realizado, primeiramente, o procedimento com a biblioteca Scikit Learn e depois com a Statsmodels.
# 
# Antes ser√° realizada a separa√ß√£o entre a vari√°vel dependente e as vari√°veis independentes.

# In[16]:


#Vari√°veis independentes
X = df.drop(['Consumo de cerveja (litros)','Data'],axis=1)
#Vari√°vel dependentes
y = df['Consumo de cerveja (litros)']


# ## Criando modelo com a Scikit Learn

# In[17]:


modelo = LinearRegression()
X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size = 0.2, random_state = 42)
modelo.fit(X_treino, y_treino)
LinearRegression() #esse √© o objeto criado


# In[18]:


# Coeficiente de Determina√ß√£o (R¬≤)
print(modelo.score(X_teste, y_teste))

# Intercepto (ou constante) do modelo.(Œ≤1)
print(modelo.intercept_)

# Coeficientes (ou par√¢metros) do modelo. (Œ≤2....)
print(modelo.coef_)


# O que √© o ùëÖ¬≤ ?
# 
# O coeficiente de determina√ß√£o √© uma propor√ß√£o que ajuda a entender o quanto as vari√°veis explicativas explicam a varia√ß√£o da m√©dia do consumo de cerveja. No sum√°rio do modelo com intercepto, o coeficiente de determina√ß√£o foi de 72.3%; j√° no modelo sem intercepto, o valor foi de 99.1%.
# 
# O ùëÖ¬≤ √© um m√©trica que varia de 0 a 1, se o modelo tiver intercepto; caso contr√°rio usa-se o ùëÖ¬≤ n√£o centrado (caso do modelo 2).
# 
# O ùëÖ¬≤ varia entre 0 e 1, ent√£o quanto maior o ùëÖ¬≤ melhor √© o modelo de regress√£o, pois teria uma maior a capacidade de explica√ß√£o.
# 
# Uma limita√ß√£o dessa medida √© que com a inser√ß√£o de regressores ao modelo o ùëÖ¬≤ tende a aumentar.

# # Criando modelo com a Statsmodels

# Nessa etapa s√£o gerado dois modelos novamente: um com intercepto (ou constante) e um sem. A presen√ßa ou n√£o do intercepto gera mudan√ßas consider√°veis nas estat√≠sticas geradas.

# In[20]:


modelo1 = (sm.OLS(y,sm.add_constant(X)).fit())
modelo1.summary(title='Sum√°rio do modelo com intercepto')


# In[21]:


modelo2 = sm.OLS(y,X).fit()
modelo2.summary(title='Sum√°rio do modelo sem intercepto')


# Ver documento WORD 

# Para os diagn√≥sticos dos modelos ser√£o gerados os res√≠duos, que s√£o a diferen√ßa entre o real e o predito pelo modelo, conforme c√≥digo abaixo

# In[22]:


modelo1.resid
modelo2.resid


# In[23]:


Predicoes = pd.DataFrame(modelo1.predict(), columns=['Predi√ß√µes 1'])
Predicoes['Predi√ß√µes 2'] = modelo2.predict()
Predicoes['Consumo de cerveja (litros)']=df['Consumo de cerveja (litros)']


# In[24]:


plt.figure()
Predicoes[['Predi√ß√µes 1','Consumo de cerveja (litros)']].plot(figsize=(15,7), color=['b','g']);


# In[26]:


plt.figure()
Predicoes[['Predi√ß√µes 2','Consumo de cerveja (litros)']].plot(figsize=(15,7), color=['r','g']);


# In[33]:


residuos1 = modelo1.resid
fig, ax = plt.subplots(2,2,figsize=(15,6))
residuos1.plot(title="Res√≠duos do modelo 1", ax=ax[0][0])
sns.histplot(residuos1,ax=ax[0][1])
plot_acf(residuos1,lags=40, ax=ax[1][0])
qqplot(residuos1,line='s', ax=ax[1][1]);


# In[34]:


residuos2 = modelo2.resid
fig, ax = plt.subplots(2,2,figsize=(15,6))
residuos2.plot(title="Res√≠duos do modelo 2", ax=ax[0][0])
sns.histplot(residuos2,ax=ax[0][1])
plot_acf(residuos2,lags=40, ax=ax[1][0])
qqplot(residuos2,line='s', ax=ax[1][1]);


# Calculando o teste Omnibus para os modelos.

# In[39]:


nome1 = ['Estat√≠stica', 'Probabilidade']
teste = sms.omni_normtest(modelo1.resid)
lzip(nome1, teste)


# In[40]:


nome2 = ['Estat√≠stica', 'Probabilidade']
teste2 = sms.omni_normtest(modelo2.resid)
lzip(nome2, teste2)


# Multicolinearidade

# In[41]:


print('N√∫mero condi√ß√£o do modelo 1 :',np.linalg.cond(modelo1.model.exog))

print('N√∫mero condi√ß√£o do modelo 2 :',np.linalg.cond(modelo2.model.exog))


# In[42]:


df1 = df
df1['residuos1'] = modelo1.resid
df1['residuos2'] = modelo2.resid


# In[44]:


fig, ax = plt.subplots(1,2,figsize=(20,7))
sns.regplot(x='Consumo de cerveja (litros)',y='residuos1',data=df1, ax=ax[0])
sns.regplot(x='Consumo de cerveja (litros)',y='residuos2',data=df1, ax=ax[1]);


# In[ ]:




